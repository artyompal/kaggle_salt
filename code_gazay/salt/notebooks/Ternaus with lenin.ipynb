{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"/home/saint/datasets/competitions/tgs-salt-identification-challenge\"\n",
    "SAVE_PATH = \"/home/saint/models/salt/\"\n",
    "SUBMISSIONS_PATH = \"/home/saint/submissions/salt/\"\n",
    "WEIGHTS_PATH = \"/home/saint/weights/ternaus_net_v2_deepglobe_buildings.pt\"\n",
    "\n",
    "MODEL_NAME = 'ternausv2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/saint/gazay/berloga-dl/lenin\")\n",
    "\n",
    "from lenin import train, test\n",
    "from src.components.TernausNetV2 import *\n",
    "from torchbearer.callbacks.checkpointers import Best\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-08-2018_20:49:59_ternausv2\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "from time import gmtime, strftime\n",
    "\n",
    "def id_generator(model_name):\n",
    "    ts = strftime(\"%d-%m-%Y_%H:%M:%S\", gmtime())\n",
    "    return ts + '_' + model_name\n",
    "\n",
    "RANDOM_KEY = id_generator(MODEL_NAME)\n",
    "print(RANDOM_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenin.datasets.salt import Dataset\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "import albumentations as aug\n",
    "pad = aug.PadIfNeeded(min_height=128, min_width=128)\n",
    "# Temp preprocessing\n",
    "def upsample(img):\n",
    "    return resize(img, (128, 128), mode='constant', preserve_range=True)\n",
    "\n",
    "# Temp preprocessing\n",
    "def downsample(img):\n",
    "    return resize(img, (101, 101), mode='constant', preserve_range=True)\n",
    "\n",
    "def img_preprocess(img):\n",
    "    #img = upsample(img)\n",
    "    img = pad(image=img)['image']\n",
    "    return img / 255.\n",
    "\n",
    "def mask_preprocess(mask):\n",
    "    #mask = upsample(mask)\n",
    "    mask = pad(image=mask)['image']\n",
    "    ones = np.expand_dims(mask, 2) > 0\n",
    "    zeros = ones != True\n",
    "    return np.concatenate((ones, zeros), axis=2)\n",
    "    \n",
    "\n",
    "dataset = Dataset(DIRECTORY, preprocessors={'image': img_preprocess, 'mask': mask_preprocess})\n",
    "#dataset.check_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    pad = aug.PadIfNeeded(min_height=128, min_width=128)\n",
    "    img = imread(DIRECTORY + '/train/masks/182ea1798b.png')\n",
    "    ones = np.expand_dims(img, 2)\n",
    "    zeros = ones == 0\n",
    "    ones = zeros != 0\n",
    "    mask = np.concatenate((ones, zeros), axis=2)\n",
    "    print(mask.shape)\n",
    "    pad(image=mask)['image'].shape    \n",
    "if False:\n",
    "    pad = aug.PadIfNeeded(min_height=128, min_width=128)\n",
    "    img = imread(DIRECTORY + '/train/images/182ea1798b.png') / 255.\n",
    "    #img[:, :, 1] = np.cumsum(img[:, :, 0], axis=0)\n",
    "    img[:, :, 1] = np.cumsum(img[:, :, 0], axis=0)\n",
    "#from skimage.transform import resize\n",
    "#resize()\n",
    "if False:\n",
    "    img = dataset.image('train-182ea1798b')\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(dataset.downsample(np.transpose(img, (1, 2, 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TernausNetV2(nn.Module):\n",
    "    fields = ('image', 'mask')\n",
    "    test_fields = ('image',)\n",
    "    \n",
    "    def __init__(self, num_classes=2,\n",
    "                       num_filters=32,\n",
    "                       is_deconv=False,\n",
    "                       num_input_channels=11):\n",
    "        super().__init__()\n",
    "        conf = {\n",
    "             \"network\": {\n",
    "                \"arch\": \"wider_resnet38\",\n",
    "                \"activation\": \"leaky_relu\",\n",
    "                \"leaky_relu_slope\": 0.01,\n",
    "                \"input_3x3\": True,\n",
    "                \"bn_mode\": \"inplace\",\n",
    "                \"classes\": 1000\n",
    "            }\n",
    "        }\n",
    "        \n",
    "#         freeze = False\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        model_params = get_model_params(conf[\"network\"])\n",
    "\n",
    "        encoder = WiderResNet(structure=[3, 3, 6, 3, 1, 1], **model_params)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            OrderedDict([('conv1', nn.Conv2d(num_input_channels, 64, 3, padding=1, bias=False))]))\n",
    "        self.conv2 = encoder.mod2\n",
    "        self.conv3 = encoder.mod3\n",
    "#         if freeze:\n",
    "#             for param in self.conv3.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        self.conv4 = encoder.mod4\n",
    "#         if freeze:\n",
    "#             for param in self.conv4.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        self.conv5 = encoder.mod5\n",
    "#         if freeze:\n",
    "#             for param in self.conv5.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        \n",
    "        dec_size = 1024\n",
    "        self.center = DecoderBlock(dec_size, num_filters * 8, num_filters * 8, is_deconv=is_deconv)\n",
    "        self.dec5 = DecoderBlock(dec_size + num_filters * 8, num_filters * 8, num_filters * 8, is_deconv=is_deconv)\n",
    "#         if freeze:\n",
    "#             for param in self.dec5.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        self.dec4 = DecoderBlock(dec_size//2 + num_filters * 8, num_filters * 8, num_filters * 8, is_deconv=is_deconv)\n",
    "#         if freeze:\n",
    "#             for param in self.dec4.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        self.dec3 = DecoderBlock(dec_size//4 + num_filters * 8, num_filters * 2, num_filters * 2, is_deconv=is_deconv)\n",
    "#         if freeze:\n",
    "#             for param in self.dec3.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        self.dec2 = DecoderBlock(dec_size//8 + num_filters * 2, num_filters * 2, num_filters, is_deconv=is_deconv)\n",
    "        self.dec1 = ConvRelu(dec_size//16 + num_filters, num_filters)\n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x = batch.image#['image']#\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(self.pool(conv1))\n",
    "        conv3 = self.conv3(self.pool(conv2))\n",
    "        conv4 = self.conv4(self.pool(conv3))\n",
    "        conv5 = self.conv5(self.pool(conv4))\n",
    "\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
    "\n",
    "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
    "        final = self.final(dec1)\n",
    "        return torch.sigmoid(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_input_channels):\n",
    "    model = TernausNetV2(num_classes=2)\n",
    "    state = torch.load(WEIGHTS_PATH)\n",
    "    state = {key.replace('module.', ''): value for key, value in state['model'].items()}\n",
    "\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    \n",
    "    model.conv1 = nn.Sequential(\n",
    "        nn.Conv2d(num_input_channels, 11, 1, padding=0, bias=False), model.conv1)\n",
    "    \n",
    "    #model.final = nn.Sequential(\n",
    "    #    model.final, nn.Conv2d(1, 1, kernel_size=3))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    return model\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = get_model(3)\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state['model'])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True#False#\n",
    "if TRAIN:\n",
    "    model = get_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchbearer/torchbearer.py:27: UserWarning: The Model class and all of its methods will be deprecated in the next version (0.2.0) in favor of the upcoming Trial API\n",
      "  warnings.warn('The Model class and all of its methods will be deprecated in the next version (0.2.0) in favor of the upcoming Trial API')\n",
      "\r",
      "0/15(t):   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/saint/gazay/berloga-dl/lenin/lenin/preloader/dataloader.py\", line 9, in collate_fn\n    values = [getattr(dataset, name)(record, augmentors[name]) for record in records]\n  File \"/home/saint/gazay/berloga-dl/lenin/lenin/preloader/dataloader.py\", line 9, in <listcomp>\n    values = [getattr(dataset, name)(record, augmentors[name]) for record in records]\n  File \"/home/saint/gazay/berloga-dl/lenin/lenin/datasets/salt.py\", line 70, in mask\n    return np.transpose(mask, (2, 0, 1)).astype('float32')\n  File \"/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\", line 575, in transpose\n    return _wrapfunc(a, 'transpose', axes)\n  File \"/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\", line 52, in _wrapfunc\n    return getattr(obj, method)(*args, **kwds)\nValueError: axes don't match array\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9068c29ec775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'BCELoss'\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[0;32m~/gazay/berloga-dl/lenin/lenin/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, dataset, **options)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchbearer/torchbearer.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, train_steps, epochs, verbose, callbacks, validation_generator, validation_steps, initial_epoch, pass_state)\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_batch_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# Zero grads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchbearer/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_sample\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_for_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchbearer/callbacks/callbacks.py\u001b[0m in \u001b[0;36m_for_list\u001b[0;34m(self, function)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_for_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchbearer/callbacks/callbacks.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(callback)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_for_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gazay/berloga-dl/lenin/lenin/preloader/train.py\u001b[0m in \u001b[0;36mon_sample\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_sample_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gazay/berloga-dl/lenin/lenin/preloader/train.py\u001b[0m in \u001b[0;36mbatch_from\u001b[0;34m(self, iterator, state)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbatch_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deep_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_TYPE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/saint/gazay/berloga-dl/lenin/lenin/preloader/dataloader.py\", line 9, in collate_fn\n    values = [getattr(dataset, name)(record, augmentors[name]) for record in records]\n  File \"/home/saint/gazay/berloga-dl/lenin/lenin/preloader/dataloader.py\", line 9, in <listcomp>\n    values = [getattr(dataset, name)(record, augmentors[name]) for record in records]\n  File \"/home/saint/gazay/berloga-dl/lenin/lenin/datasets/salt.py\", line 70, in mask\n    return np.transpose(mask, (2, 0, 1)).astype('float32')\n  File \"/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\", line 575, in transpose\n    return _wrapfunc(a, 'transpose', axes)\n  File \"/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\", line 52, in _wrapfunc\n    return getattr(obj, method)(*args, **kwds)\nValueError: axes don't match array\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    save_filepath=SAVE_PATH + ('%s.{epoch:02d}-{val_loss:.4f}.pt' % RANDOM_KEY)\n",
    "    checkpointer = Best(filepath=save_filepath)\n",
    "    train(model, dataset,\n",
    "          augment={ ('image', 'mask'): [\n",
    "              #{'type': 'HorizontalFlip'},\n",
    "              #{'type': 'Blur'},\n",
    "              #{'type': 'RandomCrop', 'height': 128, 'width': 128}\n",
    "          ] },\n",
    "          batch_size=30,\n",
    "          optimizer={ 'type': 'Adam', 'lr': 1e-4 },\n",
    "          epochs=15,\n",
    "          loss={ 'type': 'BCELoss' },\n",
    "          metrics=['loss'],\n",
    "          callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {SAVE_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAIN:\n",
    "    model_name = '19-08-2018_09:09:51_ternausv2.06-0.1506.pt'\n",
    "    model = load_model(SAVE_PATH + model_name)\n",
    "\n",
    "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf'] #,'7dfdf6eeb8','7e5a6e5013']\n",
    "def show(ids):\n",
    "    for j, img_name in enumerate(ids):\n",
    "        q = j + 1\n",
    "        img = cv2.imread(DIRECTORY + '/train/images/' + img_name + '.png')\n",
    "        img_mask = cv2.imread(DIRECTORY + '/train/masks/' + img_name + '.png')\n",
    "\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(img_mask)\n",
    "\n",
    "depths = read_csv(DIRECTORY + '/depths.csv', index_col=0)['z']\n",
    "\n",
    "img_id = '5b7c160d0d'\n",
    "orig_img = imread(DIRECTORY + '/train/images/' + img_id +'.png')\n",
    "orig_mask = imread(DIRECTORY + '/train/masks/' + img_id + '.png')\n",
    "pad = aug.PadIfNeeded(min_height=128, min_width=128)\n",
    "crop = aug.CenterCrop(height=101, width=101)\n",
    "img = pad(image=orig_img)[\"image\"] / 255.\n",
    "\n",
    "#img[:, :, 1] = np.cumsum(img[:, :, 0], axis=0)\n",
    "#img[:, :, 2] = depths[img_id] / 1000.\n",
    "\n",
    "img = np.transpose(img, (2, 0, 1)).astype('float32') \n",
    "img = np.expand_dims(img, 0)\n",
    "#print(img.shape)\n",
    "img = torch.from_numpy(img)\n",
    "\n",
    "class Batch(object):\n",
    "    pass\n",
    "batch = Batch()\n",
    "batch.image = torch.autograd.Variable(img).cuda()\n",
    "pred = model(batch)\n",
    "#pred = model({ 'image': batch.image })\n",
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pad(image=orig_mask)[\"image\"]\n",
    "ones = np.expand_dims(mask, 2) > 0\n",
    "zeros = ones != True\n",
    "#ones = !zeros\n",
    "mask = np.concatenate((ones, zeros), axis=2)\n",
    "mask[:, :, 0].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred.data[0][0].cpu().numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(mask.shape)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(orig_img)\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(orig_mask)\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(crop(image=y_pred)['image'])\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(crop(image=mask[:,:,1])['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchbearer import Model\n",
    "from lenin.augmentors.image import Augmentor\n",
    "\n",
    "def predict(model, dataset, **options):\n",
    "    batch_size = options.pop('batch_size', 32)\n",
    "\n",
    "    augmentors = {}\n",
    "    for fields, augment in options.pop('augment', {}).items():\n",
    "        if isinstance(fields, str):\n",
    "            fields = [fields]\n",
    "        augmentor = Augmentor(augment)\n",
    "        for field in fields:\n",
    "            augmentors[field] = augmentor\n",
    "\n",
    "    preload_opts = options.pop('preloader', { 'shuffle': False })\n",
    "    testgen = __preloader_predict(model, dataset, 'test_fields', dataset.test, batch_size, preload_opts, augmentors)\n",
    "\n",
    "    device = options.pop('device', 'cuda')\n",
    "    bearer = Model(model, torch.optim.Adam(model.parameters())).to(device)\n",
    "    return bearer.predict_generator(testgen)\n",
    "\n",
    "\n",
    "def __preloader_predict(model, dataset, fields_name, records, batch_size, preload_opts, augmentors={}):\n",
    "    fields = __fields(model, dataset, fields_name)\n",
    "    def collate_fn(records):\n",
    "        batch = { 'records': torch.utils.data.dataloader.default_collate(records) }\n",
    "        for name in fields:\n",
    "            if augmentors.get(name):\n",
    "                values = [getattr(dataset, name)(record, augmentors[name]) for record in records]\n",
    "            else:\n",
    "                values = [getattr(dataset, name)(record) for record in records]\n",
    "            batch[name] = torch.utils.data.dataloader.default_collate(values)\n",
    "        return batch\n",
    "    return torch.utils.data.DataLoader(records, batch_size, collate_fn=collate_fn, **preload_opts)\n",
    "\n",
    "\n",
    "def __fields(model, dataset, fields_name):\n",
    "    return getattr(model, fields_name, None) or getattr(model, 'fields', None) or dataset.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test(model, dataset,\n",
    "    augment={ ('image',): [{'type': 'PadIfNeeded', 'min_height': 128, 'min_width': 128}] }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(DIRECTORY)\n",
    "val_dataset.test = dataset.train[:2000]\n",
    "val_predictions = test(model, val_dataset,\n",
    "    augment={ ('image',): [{'type': 'PadIfNeeded', 'min_height': 128, 'min_width': 128}] }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_img = val_predictions[1803].data[0].cpu().numpy()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = np.array([crop(image=pred)['image'] for pred in val_predictions.data.cpu().numpy()[:, 0, :, :]])\n",
    "val_masks = [crop(image=val_dataset.mask(rec).numpy()[0])['image'] for rec in val_dataset.test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(val_preds[1803])\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(val_masks[1803])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "metric_by_threshold = []\n",
    "for threshold in np.linspace(0, 1, 11):\n",
    "    val_binary_prediction = (val_preds > threshold).astype(int)\n",
    "    \n",
    "    iou_values = []\n",
    "    for y_mask, p_mask in zip(val_masks, val_binary_prediction):\n",
    "        iou = jaccard_similarity_score(y_mask.flatten(), p_mask.flatten())\n",
    "        iou_values.append(iou)\n",
    "    iou_values = np.array(iou_values)\n",
    "    \n",
    "    accuracies = [\n",
    "        np.mean(iou_values > iou_threshold)\n",
    "        for iou_threshold in np.linspace(0.5, 0.95, 10)\n",
    "    ]\n",
    "    print('Threshold: %.1f, Metric: %.3f' % (threshold, np.mean(accuracies)))\n",
    "    metric_by_threshold.append((np.mean(accuracies), threshold))\n",
    "    \n",
    "best_metric, best_threshold = max(metric_by_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([crop(image=pred)['image'] for pred in predictions.data.cpu().numpy()[:, 0, :, :]])\n",
    "binary_predictions = (predictions > best_threshold).astype(int)\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "all_masks = []\n",
    "for p_mask in list(binary_predictions):\n",
    "    p_mask = rle_encoding(p_mask)\n",
    "    all_masks.append(' '.join(map(str, p_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "submit = pd.DataFrame([[rec.split('-')[1] for rec in dataset.test], all_masks]).T\n",
    "submit.columns = ['id', 'rle_mask']\n",
    "submit.to_csv('/home/saint/submissions/salt/%s.csv' % model_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = SUBMISSIONS_PATH + model_name + '.csv'\n",
    "!kaggle c submit -f {submit.replace(':', '\\:')} -m '{submit}' -c tgs-salt-identification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
