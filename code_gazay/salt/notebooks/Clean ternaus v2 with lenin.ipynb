{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/saint/\"\n",
    "DIRECTORY        = root + \"datasets/competitions/tgs-salt-identification-challenge\"\n",
    "SAVE_PATH        = root + \"models/salt/\"\n",
    "SUBMISSIONS_PATH = root + \"submissions/salt/\"\n",
    "WEIGHTS_PATH     = root + \"weights/ternaus_net_v2_deepglobe_buildings.pt\"\n",
    "\n",
    "MODEL_NAME = 'ternausv2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.0a0+5eb9d40'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# Lenin straight from repo\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/saint/berloga-dl/lenin\")\n",
    "import lenin\n",
    "from lenin import train, test\n",
    "from lenin.datasets.salt import Dataset\n",
    "\n",
    "# Ternaus net from our repo\n",
    "sys.path.insert(0, \"/home/saint/berloga-dl/salt\")\n",
    "from src.components.TernausNetV2 import *\n",
    "from src.utils import *\n",
    "\n",
    "# Torch and torchbearer\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchbearer.callbacks.checkpointers import Best\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# stdlib\n",
    "import json\n",
    "import copy\n",
    "import string\n",
    "import random\n",
    "from time import gmtime, strftime\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = get_model(3)\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state['model'])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TernausNetV2(nn.Module):\n",
    "    fields = ('image', 'mask')\n",
    "    test_fields = ('image',)\n",
    "    \n",
    "    def __init__(self, num_classes=2,\n",
    "                       num_filters=32,\n",
    "                       is_deconv=False,\n",
    "                       num_input_channels=11):\n",
    "        super().__init__()\n",
    "        conf = {\n",
    "             \"network\": {\n",
    "                \"arch\": \"wider_resnet38\",\n",
    "                \"activation\": \"leaky_relu\",\n",
    "                \"leaky_relu_slope\": 0.01,\n",
    "                \"input_3x3\": True,\n",
    "                \"bn_mode\": \"inplace\",\n",
    "                \"classes\": 1000\n",
    "            }\n",
    "        }\n",
    "        \n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        model_params = get_model_params(conf[\"network\"])\n",
    "\n",
    "        encoder = WiderResNet(structure=[3, 3, 6, 3, 1, 1], **model_params)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            OrderedDict([('conv1', nn.Conv2d(num_input_channels, 64, 3, padding=1, bias=False))]))\n",
    "        self.conv2 = encoder.mod2\n",
    "        self.conv3 = encoder.mod3\n",
    "        self.conv4 = encoder.mod4\n",
    "        self.conv5 = encoder.mod5\n",
    "        \n",
    "        dec_size = 1024\n",
    "        self.center = DecoderBlock(dec_size, num_filters * 8, num_filters * 8, is_deconv=is_deconv)\n",
    "        self.dec5 = DecoderBlock(dec_size + num_filters * 8, num_filters * 8, num_filters * 8, is_deconv=is_deconv)\n",
    "        self.dec4 = DecoderBlock(dec_size//2 + num_filters * 8, num_filters * 8, num_filters * 8, is_deconv=is_deconv)\n",
    "        self.dec3 = DecoderBlock(dec_size//4 + num_filters * 8, num_filters * 2, num_filters * 2, is_deconv=is_deconv)\n",
    "        self.dec2 = DecoderBlock(dec_size//8 + num_filters * 2, num_filters * 2, num_filters, is_deconv=is_deconv)\n",
    "        self.dec1 = ConvRelu(dec_size//16 + num_filters, num_filters)\n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def freeze(self, layer_name):\n",
    "        for param in getattr(self, layer_name).parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "    def unfreeze(self, layer_name):\n",
    "        if layer_name == 'all':\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in getattr(self, layer_name).parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x = batch.image\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(self.pool(conv1))\n",
    "        conv3 = self.conv3(self.pool(conv2))\n",
    "        conv4 = self.conv4(self.pool(conv3))\n",
    "        conv5 = self.conv5(self.pool(conv4))\n",
    "\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
    "\n",
    "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
    "        final = self.final(dec1)\n",
    "        return torch.sigmoid(final)\n",
    "\n",
    "\n",
    "def get_model(num_input_channels, load_weights=True):\n",
    "    model = TernausNetV2(num_classes=2)\n",
    "    if load_weights:\n",
    "        state = torch.load(WEIGHTS_PATH)\n",
    "        state = {key.replace('module.', ''): value for key, value in state['model'].items()}\n",
    "\n",
    "        model.load_state_dict(state)\n",
    "        model.eval()\n",
    "    \n",
    "    model.conv1 = nn.Sequential(\n",
    "        nn.Conv2d(num_input_channels, 11, 1, padding=0, bias=False), model.conv1)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre/postprocessors\n",
    "from skimage.transform import resize\n",
    "def upsample(img):\n",
    "    #img = resize(img, (128, 128), mode='constant', preserve_range=True)\n",
    "    img = pad(image=img)['image']\n",
    "    return img\n",
    "\n",
    "def downsample(img):\n",
    "    #img = resize(img, (101, 101), mode='constant', preserve_range=True)\n",
    "    img = crop(image=img)['image']\n",
    "    return img\n",
    "\n",
    "import albumentations as aug\n",
    "pad = aug.PadIfNeeded(min_height=128, min_width=128)\n",
    "crop = aug.CenterCrop(height=101, width=101)\n",
    "imgs_mean = 0.469914\n",
    "imgs_std = 0.163075\n",
    "cumsums_mean = 0.23724\n",
    "cumsums_std = 0.15206\n",
    "depths_mean = 0.52639\n",
    "depths_std = 0.214675\n",
    "# First channel – color. Second – cumsum. Third – depth with scaling\n",
    "#norm = aug.Normalize(mean=(imgs_mean,cumsums_mean,depths_mean), std=(imgs_std,cumsums_std,depths_std))\n",
    "#norm = aug.Normalize(mean=(imgs_mean,imgs_mean,imgs_mean), std=(imgs_std,imgs_std,imgs_std))\n",
    "norm = aug.Normalize(mean=(0.485,0.485,0.485), std=(0.229,0.229,0.229))\n",
    "\n",
    "def depths_channel(depth, dim):\n",
    "    depths_scaling = 0.1\n",
    "    depths_max = 959. + 128. * depths_scaling # 128 – height of scaled image\n",
    "\n",
    "    depths_arr = np.cumsum(np.ones(dim) * depths_scaling, axis=0) + depth\n",
    "    depths_arr = (depths_arr / depths_max) * 255.\n",
    "    return depths_arr\n",
    "\n",
    "def cumsum_channel(channel):\n",
    "    cumsums_max = 25755.\n",
    "\n",
    "    cumsum_arr = np.cumsum(channel, axis=0)\n",
    "    cumsum_arr = (cumsum_arr / cumsums_max) * 255.\n",
    "    return cumsum_arr\n",
    "    \n",
    "def img_preprocess(img):\n",
    "    img = upsample(img)\n",
    "    \n",
    "    # Add cumsum of img:\n",
    "    #img[:, :, 1] = cumsum_channel(img[:, :, 0])\n",
    "    # Add depth of img\n",
    "    # img[:, :, 2] = depths_channel()\n",
    "    img = norm(image=img)['image']\n",
    "    return img\n",
    "\n",
    "def img_postprocess(img):\n",
    "    img = np.transpose(img, (2, 0, 1)).astype('float32')\n",
    "    return img\n",
    "\n",
    "def mask_preprocess(mask):\n",
    "    mask = upsample(mask)\n",
    "    return mask\n",
    "    \n",
    "def mask_postprocess(mask):\n",
    "    ones = np.expand_dims(mask, 2) > 0\n",
    "    zeros = ones != True\n",
    "    mask = np.concatenate((ones, zeros), axis=2)\n",
    "    mask = np.transpose(mask, (2, 0, 1)).astype('float32')\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(DIRECTORY)\n",
    "#dataset.check_integrity() NOT WORKING\n",
    "dataset.preprocessors = { 'image': img_preprocess, 'mask': mask_preprocess }\n",
    "dataset.postprocessors = { 'image': img_postprocess, 'mask': mask_postprocess }\n",
    "#show_images(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def castF(x):\n",
    "    return x.astype(float)\n",
    "\n",
    "def castB(x):\n",
    "    return x.astype(bool)\n",
    "\n",
    "def iou_loss_core(true, pred):\n",
    "    intersection = true * pred\n",
    "    notTrue = 1 - true\n",
    "    union = true + (notTrue * pred)\n",
    "    i = np.sum(intersection, axis=-1) + 1e-07\n",
    "    u = np.sum(union, axis=-1) + 1e-07\n",
    "    return i / u\n",
    "\n",
    "def iou_ver2(true, pred):\n",
    "    tresholds = [0.5 + (i*.05)  for i in range(10)]\n",
    "\n",
    "    # flattened images (batch, pixels)\n",
    "    true.shape = (true.shape[0], -1)\n",
    "    pred.shape = (pred.shape[0], -1)\n",
    "    pred = castF(pred > 0.5)\n",
    "    \n",
    "    # total white pixels - (batch,)\n",
    "    trueSum = np.sum(true, axis=-1)\n",
    "    predSum = np.sum(pred, axis=-1)\n",
    "    \n",
    "    # has mask or not per image (batch,)\n",
    "    true1 = castF(trueSum > 1)\n",
    "    pred1 = castF(predSum > 1)\n",
    "    \n",
    "    # to get images that have mask in both true and pred\n",
    "    truePositiveMask = castB(true1 * pred1)\n",
    "\n",
    "    #separating only the possible true positives to check iou\n",
    "    testTrue = true[truePositiveMask]\n",
    "    testPred = pred[truePositiveMask]\n",
    "\n",
    "    #getting iou and threshold comparisons\n",
    "    iou = iou_loss_core(testTrue, testPred) \n",
    "    truePositives = [castF(iou > tres) for tres in tresholds]\n",
    "\n",
    "    #mean of thressholds for true positives and total sum\n",
    "    truePositives = np.mean(np.stack(truePositives, axis=-1), axis=-1)\n",
    "    truePositives = np.sum(truePositives)\n",
    "\n",
    "    #to get images that don't have mask in both true and pred\n",
    "    trueNegatives = (1 - true1) * (1 - pred1) # = 1 -true1 - pred1 + true1*pred1\n",
    "    trueNegatives = np.sum(trueNegatives) \n",
    "\n",
    "    return (truePositives + trueNegatives) / float(true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataset, step_index=0, model_name='', **options):\n",
    "    save_filepath=SAVE_PATH + ('step%i_%s.{epoch:02d}-{val_loss:.4f}.pt' % (step_index, model_name))\n",
    "    \n",
    "    print(\"Train step %i: %s\" % (step_index, save_filepath))\n",
    "    split = options.pop('split', None)\n",
    "    if split:\n",
    "        options['split'] = type(split)\n",
    "    printable_options = \"\\n\".join([(\"%s: %s\" % (str(k).ljust(12), v)) for k, v in options.items()])\n",
    "    print(\"Options:\\n%s\" % printable_options)\n",
    "    if split:\n",
    "        options['split'] = split\n",
    "    \n",
    "    checkpointer = Best(filepath=save_filepath)\n",
    "    options['callbacks'] = [checkpointer]\n",
    "    \n",
    "    [model.freeze(layer_name) for layer_name in options.pop('freeze', [])]\n",
    "    [model.unfreeze(layer_name) for layer_name in options.pop('unfreeze', [])]\n",
    "    \n",
    "    train(model, dataset, **options)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(dataset):\n",
    "    split = {}\n",
    "    if dataset.__dict__.get('stratify'):\n",
    "        split['stratify'] = [getattr(dataset, dataset.stratify)(record) for record in dataset.train]\n",
    "    return tuple(train_test_split(dataset.train, **split))\n",
    "    \n",
    "def train_sequence(dataset, model=None, steps=[], **options):\n",
    "    if not model:\n",
    "        model = get_model(3, load_weights=True)\n",
    "        timed_model_name = id_generator(MODEL_NAME)\n",
    "        print(timed_model_name)\n",
    "    \n",
    "    options['split'] = split_data(dataset)\n",
    "    for i, step in enumerate(steps):\n",
    "        for k, v in step.items():\n",
    "            options[k] = v\n",
    "        opts = copy.deepcopy(options)\n",
    "        train_step(model, dataset, step_index=i, model_name=timed_model_name, **opts)\n",
    "\n",
    "from torchbearer import metrics\n",
    "\n",
    "@metrics.default_for_key('acc')\n",
    "@metrics.lambda_metric('iou_metric_tb', on_epoch=True)\n",
    "def iou_metric_tb(y_pred, y_true):\n",
    "    pred = np.array([downsample(pr) for pr in y_pred.data.cpu().numpy()[:, 0, :, :]])\n",
    "    true = np.array([downsample(tr) for tr in y_true.data.cpu().numpy()[:, 0, :, :]])\n",
    "    return { 'running_iou': iou_ver2(true, pred) }\n",
    "    return iou_ver2(true, pred)\n",
    "\n",
    "TRAIN = True#False#\n",
    "if False:#TRAIN:\n",
    "    model = get_model(3, load_weights=True)\n",
    "    timed_model_name = id_generator(MODEL_NAME)\n",
    "    print(timed_model_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchbearer/torchbearer.py:27: UserWarning: The Model class and all of its methods will be deprecated in the next version (0.2.0) in favor of the upcoming Trial API\n",
      "  warnings.warn('The Model class and all of its methods will be deprecated in the next version (0.2.0) in favor of the upcoming Trial API')\n",
      "\r",
      "0/12(t):   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-24-234128_da2b372_ternausv2_st%i_{epoch:02d}_{val_loss:.4f}.pt\n",
      "Train step 0: /home/saint/models/salt/step0_2018-09-24-234128_da2b372_ternausv2_st%i_{epoch:02d}_{val_loss:.4f}.pt.{epoch:02d}-{val_loss:.4f}.pt\n",
      "Options:\n",
      "augment     : {('image', 'mask'): []}\n",
      "optimizer   : ('adam', {'lr': 0.0001})\n",
      "folds       : 5\n",
      "loss        : bce\n",
      "split       : <class 'tuple'>\n",
      "metrics     : ['loss']\n",
      "batch_size  : 30\n",
      "epochs      : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "0/12(t):   5%|▌         | 5/100 [00:04<01:30,  1.06it/s, running_loss=5.42]Process Process-8:\n",
      "Process Process-4:\n",
      "Process Process-7:\n",
      "Process Process-1:\n",
      "Process Process-3:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "Process Process-5:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3a9602dd0e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             ]\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mtrain_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m# One step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# loss: DICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d566913a1f90>\u001b[0m in \u001b[0;36mtrain_sequence\u001b[0;34m(dataset, model, steps, **options)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimed_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchbearer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d566913a1f90>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, dataset, step_index, model_name, **options)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unfreeze'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/berloga-dl/lenin/lenin/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, dataset, **options)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchbearer/torchbearer.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, train_steps, epochs, verbose, callbacks, validation_generator, validation_steps, initial_epoch, pass_state)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# Loss Calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOSS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCRITERION\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_PRED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_TRUE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1622\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    options = {\n",
    "        'augment': { ('image', 'mask'): [\n",
    "            #{'type': 'PadIfNeeded', 'min_height': 128, 'min_width': 202},\n",
    "            #{'type': 'RandomCrop', 'height': 128, 'width': 128},\n",
    "            #{'type': 'HorizontalFlip'},\n",
    "            #{'type': 'Blur'},\n",
    "        ] },\n",
    "        'batch_size': 30,\n",
    "        'optimizer': ('adam', { 'lr': 1e-4 }),\n",
    "        'epochs': 12,\n",
    "        'folds': 5,\n",
    "        'loss': 'bce',\n",
    "        'metrics': ['loss'] #, 'acc']\n",
    "    }\n",
    "    \n",
    "    FOLDS = False#True#\n",
    "    STEPS = True\n",
    "    if STEPS:\n",
    "        # One step\n",
    "        # loss: BCE\n",
    "        #   No aug: 0.169-0.17\n",
    "        #   HorizontalFlip: 0.146-0.149\n",
    "        #   Pad(Horizontally to 202)+RandCrop: 0.151-0.155\n",
    "        #   HorizontalFlip+Pad(Horizontally to 202)+RandCrop: 0.137-0.142-0.166 -- 0.144-0.152 (0.763 LB)\n",
    "        if True:\n",
    "            steps = [\n",
    "                {}\n",
    "            ]\n",
    "            train_sequence(dataset, steps=steps, **options)\n",
    "        # One step\n",
    "        # loss: DICE\n",
    "        #   No aug: 0.0473-0.0479 (0.775 LB)\n",
    "        #   HorizontalFlip: \n",
    "        #   Pad(Horizontally to 202)+RandCrop: 0.0588\n",
    "        elif False:\n",
    "            steps = [\n",
    "                {}\n",
    "            ]\n",
    "            options['loss'] = 'dice'\n",
    "            train_sequence(dataset, steps=steps, **options)\n",
    "        # One step\n",
    "        # loss: BCE WITH DICE\n",
    "        #   No aug: 0.2263 / 0.207\n",
    "        #   HorizontalFlip: 0.2078 (0.782 LB)\n",
    "        #   Pad(Horizontally to 202)+RandCrop: 0.161-0.174 (overfit - 0.77 LB)\n",
    "        #   Blur: 0.236\n",
    "        #   Normalization by images (all 3 channels identic):\n",
    "        #     No aug:\n",
    "        elif False:\n",
    "            steps = [\n",
    "                {}\n",
    "            ]\n",
    "            options['loss'] = 'bce_with_dice'\n",
    "            train_sequence(dataset, steps=steps, **options)\n",
    "        # Freezing all except conv1 and dec1, final\n",
    "        # Decreasing LR and unfreezing form sides to center\n",
    "        # loss: BCE\n",
    "        #   No aug: 0.19-0.191\n",
    "        #   HorizontalFlip: 0.163-0.164\n",
    "        elif False:\n",
    "            steps = [\n",
    "                {\n",
    "                    'epochs': 2,\n",
    "                    'optimizer': ('adam', { 'lr': 1e-3 }),\n",
    "                    'freeze': ['conv2', 'conv3', 'conv4', 'conv5', 'center', 'dec5', 'dec4', 'dec3', 'dec2']\n",
    "                },\n",
    "                {\n",
    "                    'optimizer': ('adam', { 'lr': 0.5e-3 }),\n",
    "                    'freeze': [],\n",
    "                    'unfreeze': ['conv2', 'dec2']\n",
    "                },\n",
    "                {\n",
    "                    'optimizer': ('adam', { 'lr': 1e-4 }),\n",
    "                    'unfreeze': ['conv3', 'dec3']\n",
    "                },\n",
    "                {\n",
    "                    'optimizer': ('adam', { 'lr': 0.5e-4 }),\n",
    "                    'unfreeze': ['conv4', 'dec4']\n",
    "                },\n",
    "                {\n",
    "                    'epochs': 5,\n",
    "                    'optimizer': ('adam', { 'lr': 1e-5 }),\n",
    "                    'unfreeze': ['conv5', 'center', 'dec5']\n",
    "                }\n",
    "            ]\n",
    "            train_sequence(dataset, steps=steps, **options)\n",
    "        # BCE\n",
    "        # Freezing all except conv1 and dec1, final\n",
    "        # Increasing LR and unfreezing form sides to center\n",
    "        # loss: BCE\n",
    "        #   No aug: 0.171-0.18\n",
    "        elif False: \n",
    "            steps = [\n",
    "                {\n",
    "                    'epochs': 2,\n",
    "                    'optimizer': ('adam', { 'lr': 1e-5 }),\n",
    "                    'freeze': ['conv2', 'conv3', 'conv4', 'conv5', 'center', 'dec5', 'dec4', 'dec3', 'dec2']\n",
    "                },\n",
    "                {\n",
    "                    'optimizer': ('adam', { 'lr': 0.5e-4 }),\n",
    "                    'freeze': [],\n",
    "                    'unfreeze': ['conv2', 'dec2']\n",
    "                },\n",
    "                {\n",
    "                    'optimizer': ('adam', { 'lr': 1e-4 }),\n",
    "                    'unfreeze': ['conv3', 'dec3']\n",
    "                },\n",
    "                {\n",
    "                    'optimizer': ('adam', { 'lr': 0.5e-3 }),\n",
    "                    'unfreeze': ['conv4', 'dec4']\n",
    "                },\n",
    "                {\n",
    "                    'epochs': 5,\n",
    "                    'optimizer': ('adam', { 'lr': 1e-3 }),\n",
    "                    'unfreeze': ['conv5', 'center', 'dec5']\n",
    "                }   \n",
    "            ]\n",
    "            train_sequence(dataset, steps=steps, **options)\n",
    "        # Freezing all except conv1 and dec1, final\n",
    "        # Restart LR in every step, unfreezing form sides to center\n",
    "        # loss: BCE\n",
    "        #   No aug: 0.178-0.19\n",
    "        elif False:\n",
    "            steps = [\n",
    "                {\n",
    "                    'epochs': 2,\n",
    "                    'optimizer': ('adam', { 'lr': 1e-4 }),\n",
    "                    'freeze': ['conv2', 'conv3', 'conv4', 'conv5', 'center', 'dec5', 'dec4', 'dec3', 'dec2']\n",
    "                },\n",
    "                {\n",
    "                    'freeze': [],\n",
    "                    'unfreeze': ['conv2', 'dec2']\n",
    "                },\n",
    "                {\n",
    "                    'unfreeze': ['conv3', 'dec3']\n",
    "                },\n",
    "                {\n",
    "                    'unfreeze': ['conv4', 'dec4']\n",
    "                },\n",
    "                {\n",
    "                    'epochs': 5,\n",
    "                    'unfreeze': ['conv5', 'center', 'dec5']\n",
    "                }\n",
    "            ]\n",
    "            train_sequence(dataset, steps=steps, **options)\n",
    "        # Freezing all except center, final\n",
    "        # Decreasing LR and unfreezing form center to sides\n",
    "        # loss: BCE\n",
    "        #   No aug: 0.167-0.174\n",
    "        elif False:\n",
    "            steps = [\n",
    "                {\n",
    "                    'epochs': 2,\n",
    "                    'optimizer': ('adam', { 'lr': 1e-3 }),\n",
    "                    'freeze': ['conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'dec5', 'dec4', 'dec3', 'dec2', 'dec1']\n",
    "                },\n",
    "                {\n",
    "                    'freeze': [],\n",
    "                    'optimizer': ('adam', { 'lr': 0.5e-3 }),\n",
    "                    'unfreeze': ['conv5', 'dec5']\n",
    "                },\n",
    "                {\n",
    "                    'optimizer': ('adam', { 'lr': 1e-4 }),\n",
    "                    'unfreeze': ['conv4', 'dec4']\n",
    "                },\n",
    "                {\n",
    "                    'optimizer': ('adam', { 'lr': 0.5e-4 }),\n",
    "                    'unfreeze': ['conv3', 'dec3']\n",
    "                },\n",
    "                {\n",
    "                    'epochs': 5,\n",
    "                    'optimizer': ('adam', { 'lr': 1e-5 }),\n",
    "                    'unfreeze': ['conv1', 'conv2', 'dec2', 'dec1']\n",
    "                }\n",
    "            ]\n",
    "            train_sequence(dataset, steps=steps, **options)\n",
    "    elif FOLDS:\n",
    "        # Trying folds\n",
    "        import copy\n",
    "        from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "        nets = []\n",
    "        folds = options.pop('folds', 3)\n",
    "\n",
    "        if dataset.stratify:\n",
    "            stratify = [getattr(dataset, dataset.stratify)(record) for record in dataset.train]\n",
    "            splits = StratifiedKFold(n_splits=folds).split(dataset.train, stratify)\n",
    "        else:\n",
    "            splits = KFold(n_splits=folds).split(dataset.train)\n",
    "\n",
    "        all_records = np.array(dataset.train)\n",
    "        for i, (train_ids, valid_ids) in enumerate(splits):\n",
    "            print('Fold %i' % i)\n",
    "            train_records = all_records[train_ids]\n",
    "            valid_records = all_records[valid_ids]\n",
    "\n",
    "            options['split'] = (train_records, valid_records)\n",
    "            fold_net = copy.deepcopy(model)\n",
    "            save_filepath=SAVE_PATH + ('f%i' % i) + ('%s.{epoch:02d}-{val_loss:.4f}.pt' % timed_model_name)\n",
    "            checkpointer = Best(filepath=save_filepath)\n",
    "            options['callbacks'] = [checkpointer]\n",
    "            train(fold_net, dataset, **options)\n",
    "            nets.append(fold_net)\n",
    "    else:\n",
    "        train_step(model, dataset, step_index=0, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la {SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "if not TRAIN:\n",
    "    model_name = 'step0_21-09-2018_00:02:55_ternausv2.11-0.2455.pt'\n",
    "    model = load_model(SAVE_PATH + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 'train-5b7c160d0d'\n",
    "orig_img = dataset.image(img_id)\n",
    "orig_mask = dataset.mask(img_id)\n",
    "img = dataset.postprocessors['image'](dataset.preprocessors['image'](orig_img))\n",
    "img = np.expand_dims(img, 0)\n",
    "img = torch.from_numpy(img)\n",
    "\n",
    "batch = TestBatch()\n",
    "batch.image = torch.autograd.Variable(img).cuda()\n",
    "pred = model(batch).data[0].cpu().numpy()[0]\n",
    "assert pred.shape, (128, 128)\n",
    "pred = downsample(pred)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(orig_img)\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(orig_mask)\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(pred)\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(edges(pred, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(DIRECTORY)\n",
    "val_dataset.preprocessors = { 'image': img_preprocess, 'mask': mask_preprocess }\n",
    "val_dataset.postprocessors = { 'image': img_postprocess, 'mask': mask_postprocess }\n",
    "val_dataset.test = dataset.train[:2000]\n",
    "val_predictions = test(model, val_dataset,\n",
    "    augment={ ('image',): [{'type': 'PadIfNeeded', 'min_height': 128, 'min_width': 128}] }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = np.array([downsample(pred) for pred in val_predictions.data.cpu().numpy()[:, 0, :, :]])\n",
    "val_masks = np.array([downsample(val_dataset.mask(rec)) for rec in val_dataset.test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds.shape = (2000, -1)\n",
    "val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_ver2(val_masks, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(dataset, model, threshold=threshold_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_best = 0.5\n",
    "\n",
    "predictions = test(model, dataset, batch_size=25)\n",
    "predictions = np.array([downsample(pred) for pred in predictions.data.cpu().numpy()[:, 0, :, :]])\n",
    "binary_predictions = (predictions > threshold_best).astype(int)\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "all_masks = []\n",
    "for p_mask in list(binary_predictions):\n",
    "    p_mask = rle_encoding(p_mask)\n",
    "    all_masks.append(' '.join(map(str, p_mask)))\n",
    "\n",
    "submit = pd.DataFrame([[rec.split('-')[1] for rec in dataset.test], all_masks]).T\n",
    "submit.columns = ['id', 'rle_mask']\n",
    "submit.to_csv('/home/saint/submissions/salt/%s.csv' % model_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = SUBMISSIONS_PATH + model_name + '.csv'\n",
    "!kaggle c submit -f {submit.replace(':', '\\:')} -m '{submit}' -c tgs-salt-identification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
